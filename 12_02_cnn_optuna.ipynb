{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EhZMtSdM3W4N",
        "outputId": "e6497a3e-5652-49f5-c26c-fd3752b8a92f"
      },
      "outputs": [],
      "source": [
        "# !pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKj08wBQfuDd"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCrakIjRollf",
        "outputId": "668efded-6d48-4deb-8e18-7434c83eca85"
      },
      "outputs": [],
      "source": [
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DYn2_6J2oYF",
        "outputId": "e56e0f86-29c6-40a3-dd99-66220991d9ba"
      },
      "outputs": [],
      "source": [
        "# Check for GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "7lZjGSXR35Qz",
        "outputId": "018ebb83-fa9d-4ab2-f6d3-2d3876c329e8"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/fashion-mnist_train.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u70Dnz9f36Yo",
        "outputId": "a0548300-ecc9-4e1d-ad20-6ca5d12338e9"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jFkhK1dvyzW8",
        "outputId": "9b4864ad-c1bc-4b59-ad21-82cc137b4e43"
      },
      "outputs": [],
      "source": [
        "# Create a 4x4 grid of images\n",
        "fig, axes = plt.subplots(4, 4, figsize=(10, 10))\n",
        "fig.suptitle(\"First 16 Images\", fontsize=16)\n",
        "\n",
        "# Plot the first 16 images from the dataset\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    img = df.iloc[i, 1:].values.reshape(28, 28)  # Reshape to 28x28\n",
        "    ax.imshow(img)  # Display in grayscale\n",
        "    ax.axis('off')  # Remove axis for a cleaner look\n",
        "    ax.set_title(f\"Label: {df.iloc[i, 0]}\")  # Show the label\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.96])  # Adjust layout to fit the title\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPoB2jkn3-8V"
      },
      "outputs": [],
      "source": [
        "# train test split\n",
        "\n",
        "X = df.iloc[:, 1:].values\n",
        "y = df.iloc[:, 0].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtmEmavE4K7V"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zRx5nPbkoM-"
      },
      "outputs": [],
      "source": [
        "X_train = X_train/255.0\n",
        "X_test = X_test/255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g21Og7ayuOjE"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "# Define data augmentations for the training dataset\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomAffine(0, translate=(0.1, 0.1)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oISAHnU5GnT"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, features, labels, transform=None):\n",
        "        self.features = torch.tensor(features, dtype=torch.float32).reshape(-1, 1, 28, 28)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        feature, label = self.features[index], self.labels[index]\n",
        "        if self.transform:\n",
        "            feature = self.transform(feature.squeeze(0).numpy())  # Apply transform\n",
        "        return feature, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Thpv_XzP5z_b"
      },
      "outputs": [],
      "source": [
        "# Use augmentations in training data\n",
        "train_dataset = CustomDataset(X_train, y_train, transform=train_transform)\n",
        "test_dataset = CustomDataset(X_test, y_test, transform=test_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xgn1tw9I6fPT"
      },
      "outputs": [],
      "source": [
        "# Define the dynamic CNN model class\n",
        "class DynamicCNN(nn.Module):\n",
        "    def __init__(self, num_conv_layers, num_filters, kernel_size, num_fc_layers, fc_layer_size, dropout_rate):\n",
        "        super(DynamicCNN, self).__init__()\n",
        "        layers = []\n",
        "        in_channels = 1  # Grayscale images have 1 input channel\n",
        "\n",
        "        # Convolutional layers\n",
        "        for _ in range(num_conv_layers):\n",
        "            layers.append(nn.Conv2d(in_channels, num_filters, kernel_size=kernel_size, padding='same'))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.BatchNorm2d(num_filters))\n",
        "            layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "            in_channels = num_filters  # Update input channels for the next layer\n",
        "\n",
        "        self.features = nn.Sequential(*layers)\n",
        "\n",
        "        # Fully connected layers\n",
        "        fc_layers = [nn.Flatten()]\n",
        "        input_size = num_filters * (28 // (2 ** num_conv_layers)) ** 2\n",
        "        for _ in range(num_fc_layers):\n",
        "            fc_layers.append(nn.Linear(input_size, fc_layer_size))\n",
        "            fc_layers.append(nn.ReLU())\n",
        "            fc_layers.append(nn.Dropout(dropout_rate))\n",
        "            input_size = fc_layer_size\n",
        "        fc_layers.append(nn.Linear(input_size, 10))  # Final layer for 10 classes\n",
        "\n",
        "        self.classifier = nn.Sequential(*fc_layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTVOaQ_T2O98"
      },
      "outputs": [],
      "source": [
        "# Define the objective function for Optuna\n",
        "def objective(trial):\n",
        "    # Hyperparameters to tune\n",
        "    num_conv_layers = trial.suggest_int('num_conv_layers', 1, 3)\n",
        "    num_filters = trial.suggest_categorical('num_filters', [16, 32, 64, 128])\n",
        "    kernel_size = trial.suggest_categorical('kernel_size', [3, 5])\n",
        "    num_fc_layers = trial.suggest_int('num_fc_layers', 1, 3)\n",
        "    fc_layer_size = trial.suggest_categorical('fc_layer_size', [64, 128, 256])\n",
        "    dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.5)\n",
        "    weight_decay = trial.suggest_loguniform('weight_decay', 1e-5, 1e-2)\n",
        "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
        "    optimizer_name = trial.suggest_categorical('optimizer', ['SGD', 'Adam', 'RMSprop'])\n",
        "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
        "    num_epochs = trial.suggest_int('num_epochs', 10, 30)\n",
        "\n",
        "    # Model\n",
        "    model = DynamicCNN(num_conv_layers, num_filters, kernel_size, num_fc_layers, fc_layer_size, dropout_rate).to(device)\n",
        "\n",
        "    # Data\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Optimizer\n",
        "    if optimizer_name == 'SGD':\n",
        "        optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "    elif optimizer_name == 'Adam':\n",
        "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "    elif optimizer_name == 'RMSprop':\n",
        "        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    # Loss function\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for batch_features, batch_labels in train_loader:\n",
        "            batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_features)\n",
        "            loss = criterion(outputs, batch_labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_features, batch_labels in test_loader:\n",
        "            batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "            outputs = model(batch_features)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += batch_labels.size(0)\n",
        "            correct += (predicted == batch_labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Al0voIIh2TdS",
        "outputId": "3b878a6d-b26a-424f-dbf0-2afc349a71f7"
      },
      "outputs": [],
      "source": [
        "# Run the Optuna study\n",
        "pruner = optuna.pruners.MedianPruner()\n",
        "study = optuna.create_study(direction='maximize', pruner=pruner)\n",
        "study.optimize(objective, n_trials=50)  # Run 50 trials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6PHexkUt2Wjz"
      },
      "outputs": [],
      "source": [
        "# Print the best hyperparameters and accuracy\n",
        "print(\"Best hyperparameters:\", study.best_params)\n",
        "print(\"Best accuracy:\", study.best_value)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
