{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "EhZMtSdM3W4N"
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NCrakIjRollf",
    "outputId": "74cb5796-b30d-42ba-97b5-d4fac2f85802"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Check for GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3DYn2_6J2oYF",
    "outputId": "a72dfb04-e79e-4197-afb0-e1ccfe8f2174"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('dataset/fmnist_small.csv')\n",
    "df.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "7lZjGSXR35Qz",
    "outputId": "3966c3a3-4282-4531-be85-c089d483613b"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u70Dnz9f36Yo",
    "outputId": "1708031d-8e65-49b4-a093-fc4c7eae94f2"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Create a 4x4 grid of images\n",
    "fig, axes = plt.subplots(4, 4, figsize=(10, 10))\n",
    "fig.suptitle(\"First 16 Images\", fontsize=16)\n",
    "\n",
    "# Plot the first 16 images from the dataset\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img = df.iloc[i, 1:].values.reshape(28, 28)  # Reshape to 28x28\n",
    "    ax.imshow(img)  # Display in grayscale\n",
    "    ax.axis('off')  # Remove axis for a cleaner look\n",
    "    ax.set_title(f\"Label: {df.iloc[i, 0]}\")  # Show the label\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])  # Adjust layout to fit the title\n",
    "plt.show()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jFkhK1dvyzW8",
    "outputId": "7e823972-1aa2-45e3-dfb7-0d2378ec9e2b"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# train test split\n",
    "\n",
    "X = df.iloc[:, 1:].values\n",
    "y = df.iloc[:, 0].values"
   ],
   "metadata": {
    "id": "CPoB2jkn3-8V"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "id": "CtmEmavE4K7V"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(X_train) # this will be for __len__ ",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## We will be using VGG16 pretrained model\n",
    "It's trained on 1.6M real world images from ImageNet\n",
    "\n",
    "[Pytorch Documentation](https://docs.pytorch.org/vision/main/models/generated/torchvision.models.vgg16.html#:~:text=IMAGENET1K_FEATURES.transforms%20and-,perform%20the%20following%20preprocessing,-operations%3A%20Accepts%20PIL)\n",
    "\n",
    "According to that we need to apply transformation on input"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# transformations\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "custom_transform = transforms.Compose([\n",
    "    transforms.Resize(256),     # resizes to (3,256,256)\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),      # PIL Image or numpy.ndarray to Tensor and scales to 0~1\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ],
   "metadata": {
    "id": "qv-FkE9TfIxQ"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "  def __init__(self, features, labels, transform):\n",
    "    self.features = features\n",
    "    self.labels = labels\n",
    "    self.transform = transform\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.features)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    # resize to (28, 28)\n",
    "    image = self.features[index].reshape(28,28)\n",
    "\n",
    "    # change datatype to np.uint8\n",
    "    image = image.astype(np.uint8)\n",
    "\n",
    "    # change black&white to color -> (H,W,C) -> (C,H,W)\n",
    "    image = np.stack([image]*3, axis=-1)\n",
    "\n",
    "    # convert array to PIL image\n",
    "    image = Image.fromarray(image)\n",
    "\n",
    "    # apply transforms\n",
    "    image = self.transform(image)\n",
    "\n",
    "    # return\n",
    "    return image, torch.tensor(self.labels[index], dtype=torch.long)"
   ],
   "metadata": {
    "id": "0oISAHnU5GnT"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "train_dataset = CustomDataset(X_train, y_train, transform=custom_transform)"
   ],
   "metadata": {
    "id": "Thpv_XzP5z_b"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "test_dataset = CustomDataset(X_test, y_test, transform=custom_transform)"
   ],
   "metadata": {
    "id": "kqAkmOzV58TD"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, pin_memory=True)"
   ],
   "metadata": {
    "id": "UW-HhV4x5_PD"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# fetch the pretrained model\n",
    "from torchvision.models import vgg16, VGG16_Weights\n",
    "\n",
    "vgg16 = vgg16(weights=VGG16_Weights.DEFAULT)"
   ],
   "metadata": {
    "id": "Xgn1tw9I6fPT",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a095ed66-4cf0-4e47-d8f9-5f35ad5d7af9"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "vgg16"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "63qVLx2cnckV",
    "outputId": "6ff920bf-9760-442f-ed07-4a5a55a115ac"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "for param in vgg16.features.parameters():\n",
    "  param.requires_grad=False"
   ],
   "metadata": {
    "id": "nUicCYnKnpWa"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "vgg16.classifier = nn.Sequential(\n",
    "    nn.Linear(25088, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(512, 10)\n",
    ")"
   ],
   "metadata": {
    "id": "7tw-jSB7n4Ub"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "vgg16 = vgg16.to(device)"
   ],
   "metadata": {
    "id": "aA90gLbnolUe"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "learning_rate = 0.0001\n",
    "epochs = 20"
   ],
   "metadata": {
    "id": "z3LfMWb698O5"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(vgg16.classifier.parameters(), lr=learning_rate)"
   ],
   "metadata": {
    "id": "JpbU_UCp9N1r"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# training loop\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "  total_epoch_loss = 0\n",
    "\n",
    "  for batch_features, batch_labels in train_loader:\n",
    "\n",
    "    # move data to gpu\n",
    "    batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "\n",
    "    # forward pass\n",
    "    outputs = vgg16(batch_features)\n",
    "\n",
    "    # print(outputs.shape)\n",
    "    # print(batch_labels.shape)\n",
    "\n",
    "    # calculate loss\n",
    "    loss = criterion(outputs, batch_labels)\n",
    "\n",
    "    # back pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # update grads\n",
    "    optimizer.step()\n",
    "\n",
    "    total_epoch_loss = total_epoch_loss + loss.item()\n",
    "\n",
    "    # break\n",
    "\n",
    "  avg_loss = total_epoch_loss/len(train_loader)\n",
    "  print(f'Epoch: {epoch + 1} , Loss: {avg_loss}')\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0UpCVk9X-JaI",
    "outputId": "731246f1-baa5-4cc2-faa9-2205742599d6"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "vgg16.eval()",
   "metadata": {
    "id": "CA6B2YPYAOtu"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# evaluation on test data\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "  for batch_features, batch_labels in test_loader:\n",
    "\n",
    "    # move data to gpu\n",
    "    batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "\n",
    "    outputs = vgg16(batch_features)\n",
    "\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    total = total + batch_labels.shape[0]\n",
    "\n",
    "    correct = correct + (predicted == batch_labels).sum().item()\n",
    "\n",
    "print(correct/total)"
   ],
   "metadata": {
    "id": "Xwirkg4PPNhB"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# evaluation on training data\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "  for batch_features, batch_labels in train_loader:\n",
    "\n",
    "    # move data to gpu\n",
    "    batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "\n",
    "    outputs = vgg16(batch_features)\n",
    "\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    total = total + batch_labels.shape[0]\n",
    "\n",
    "    correct = correct + (predicted == batch_labels).sum().item()\n",
    "\n",
    "print(correct/total)"
   ],
   "metadata": {
    "id": "J5edAjvgr8tB"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "mvmh1sLJLCCb"
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
