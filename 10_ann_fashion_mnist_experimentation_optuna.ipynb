{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T12:44:12.503323Z",
     "start_time": "2025-06-18T12:43:55.926602Z"
    },
    "id": "EhZMtSdM3W4N"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T12:44:12.538259Z",
     "start_time": "2025-06-18T12:44:12.508335Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NCrakIjRollf",
    "outputId": "22de98c2-41ba-44f9-9d29-64c63f2e085c"
   },
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T12:44:12.599684Z",
     "start_time": "2025-06-18T12:44:12.541810Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3DYn2_6J2oYF",
    "outputId": "545c3445-56fc-460f-b708-6f929fc1a633"
   },
   "outputs": [],
   "source": [
    "# Check for GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T12:44:17.957140Z",
     "start_time": "2025-06-18T12:44:12.603215Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "7lZjGSXR35Qz",
    "outputId": "08b6d3a0-8d3e-4be3-ee8d-8f48a4e986ef"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/fashion-mnist_train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T12:44:17.975409Z",
     "start_time": "2025-06-18T12:44:17.963970Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u70Dnz9f36Yo",
    "outputId": "744b3a42-565f-4fd9-8ca0-54c479728f33"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T12:44:20.189577Z",
     "start_time": "2025-06-18T12:44:17.979679Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jFkhK1dvyzW8",
    "outputId": "8c70a48f-a0ce-4856-baa3-cad1a836e844"
   },
   "outputs": [],
   "source": [
    "# Create a 4x4 grid of images\n",
    "fig, axes = plt.subplots(4, 4, figsize=(10, 10))\n",
    "fig.suptitle(\"First 16 Images\", fontsize=16)\n",
    "\n",
    "# Plot the first 16 images from the dataset\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img = df.iloc[i, 1:].values.reshape(28, 28)  # Reshape to 28x28\n",
    "    ax.imshow(img)  # Display in grayscale\n",
    "    ax.axis('off')  # Remove axis for a cleaner look\n",
    "    ax.set_title(f\"Label: {df.iloc[i, 0]}\")  # Show the label\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])  # Adjust layout to fit the title\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T12:44:20.199765Z",
     "start_time": "2025-06-18T12:44:20.191666Z"
    },
    "id": "CPoB2jkn3-8V"
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "\n",
    "X = df.iloc[:, 1:].values\n",
    "y = df.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T12:44:21.320342Z",
     "start_time": "2025-06-18T12:44:20.203781Z"
    },
    "id": "CtmEmavE4K7V"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T12:44:21.502341Z",
     "start_time": "2025-06-18T12:44:21.324039Z"
    },
    "id": "6zRx5nPbkoM-"
   },
   "outputs": [],
   "source": [
    "X_train = X_train/255.0\n",
    "X_test = X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T12:44:21.512721Z",
     "start_time": "2025-06-18T12:44:21.504858Z"
    },
    "id": "0oISAHnU5GnT"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, features, labels):\n",
    "\n",
    "        # Convert to PyTorch tensors\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.features[index], self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T12:44:21.566639Z",
     "start_time": "2025-06-18T12:44:21.515832Z"
    },
    "id": "Thpv_XzP5z_b"
   },
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T12:44:21.591226Z",
     "start_time": "2025-06-18T12:44:21.570300Z"
    },
    "id": "kqAkmOzV58TD"
   },
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T12:44:21.608791Z",
     "start_time": "2025-06-18T12:44:21.595752Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uZq-FOc9Zdw4",
    "outputId": "6a630667-030a-4d12-d616-93b35db1e886"
   },
   "outputs": [],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T12:44:21.628711Z",
     "start_time": "2025-06-18T12:44:21.615091Z"
    },
    "id": "ls-aqVizmTFm"
   },
   "outputs": [],
   "source": [
    "class MyNN(nn.Module):\n",
    "    # Dynamic / Configurable model -  trying multiple model depths/sizes OR scripting experiments or tuning\n",
    "    def __init__(self, input_dim, output_dim, num_hidden_layers, neurons_per_layer, dropout_rate): # hidden_layer_sizes_list <- combines num_hidden_layers & neurons_per_layer\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        for i in range(num_hidden_layers): # making hidden layers - dynamic\n",
    "\n",
    "            layers.append(nn.Linear(input_dim, neurons_per_layer))\n",
    "            layers.append(nn.BatchNorm1d(neurons_per_layer))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            input_dim = neurons_per_layer # update input_dim for next layer\n",
    "\n",
    "        layers.append(nn.Linear(neurons_per_layer, output_dim))\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "mvmh1sLJLCCb",
    "outputId": "6c25e9ea-07f9-40e3-c806-747b7a771790"
   },
   "outputs": [],
   "source": [
    "# !pip install optuna mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EAhkvuVVrBT3",
    "outputId": "bffa6676-478b-4adf-cbd2-ca0f2c6faef3"
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "study = optuna.create_study(direction='maximize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective function\n",
    "def objective(trial):\n",
    "\n",
    "    # next hyperparameter values from the search space\n",
    "    num_hidden_layers = trial.suggest_int(\"num_hidden_layers\", 1, 5)\n",
    "    neurons_per_layer = trial.suggest_int(\"neurons_per_layer\", 8, 128, step=8)\n",
    "    epochs = trial.suggest_int(\"epochs\", 10, 50, step=10)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5, step=0.1)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64, 128])\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", ['Adam', 'SGD', 'RMSprop'])\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1e-3, log=True)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "    # model init\n",
    "    input_dim = 784\n",
    "    output_dim = 10\n",
    "\n",
    "    model = MyNN(input_dim, output_dim, num_hidden_layers, neurons_per_layer, dropout_rate)\n",
    "    model.to(device)\n",
    "\n",
    "    # optimizer selection\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = optim.SGD(model.parameters(), lr=0.1, weight_decay=1e-4) # ??\n",
    "    # optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay) # why not here?\n",
    "\n",
    "    if optimizer_name == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'SGD':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    else:\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    # training loop\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        for batch_features, batch_labels in train_loader:\n",
    "\n",
    "            # move data to gpu\n",
    "            batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "\n",
    "            # forward pass\n",
    "            outputs = model(batch_features)\n",
    "\n",
    "            # calculate loss\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "\n",
    "            # back pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # update grads\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "    # evaluation\n",
    "    model.eval()\n",
    "    # evaluation on test data\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch_features, batch_labels in test_loader:\n",
    "\n",
    "            # move data to gpu\n",
    "            batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "\n",
    "            outputs = model(batch_features)\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            total = total + batch_labels.shape[0]\n",
    "\n",
    "            correct = correct + (predicted == batch_labels).sum().item()\n",
    "\n",
    "        accuracy = correct/total\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.optimize(objective, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x-bubVWNyO13",
    "outputId": "3d1dd078-ec07-4efe-f9ba-b0d61c6d3043"
   },
   "outputs": [],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J5NrXu6Xyc5r",
    "outputId": "e9dc971e-15da-4d9e-d2ef-874e8b3553b6"
   },
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TNSVCFZYyhsn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better implementation - with optuna+mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supress few warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", module=\"mlflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T13:56:34.269598Z",
     "start_time": "2025-06-18T12:44:21.633917Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import optuna\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from optuna.integration.mlflow import MLflowCallback\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Seed setup for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed()\n",
    "\n",
    "# Flexible Neural Network\n",
    "class MyNN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_layer_sizes, dropout_rate):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for hidden_dim in hidden_layer_sizes:\n",
    "            layers.extend([\n",
    "                nn.Linear(input_dim, hidden_dim),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ])\n",
    "            input_dim = hidden_dim\n",
    "        layers.append(nn.Linear(input_dim, output_dim))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    num_hidden_layers = trial.suggest_int(\"num_hidden_layers\", 1, 5)\n",
    "    neurons_per_layer = trial.suggest_int(\"neurons_per_layer\", 8, 128, step=8)\n",
    "    hidden_layer_sizes = [neurons_per_layer] * num_hidden_layers\n",
    "\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5, step=0.1)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1e-3, log=True)\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", ['Adam', 'SGD', 'RMSprop'])\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64, 128])\n",
    "    epochs = trial.suggest_int(\"epochs\", 10, 50, step=10)\n",
    "\n",
    "    # Data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "    # Model\n",
    "    input_dim = 784\n",
    "    output_dim = 10\n",
    "    model = MyNN(input_dim, output_dim, hidden_layer_sizes, dropout_rate).to(device)\n",
    "\n",
    "    # Loss & Optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    if optimizer_name == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'SGD':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    else:\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    # MLflow logging\n",
    "    with mlflow.start_run(nested=True):\n",
    "        mlflow.set_tag(\"trial_id\", trial.number)\n",
    "        mlflow.log_params({\n",
    "            \"num_hidden_layers\": num_hidden_layers,\n",
    "            \"neurons_per_layer\": neurons_per_layer,\n",
    "            \"dropout_rate\": dropout_rate,\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"weight_decay\": weight_decay,\n",
    "            \"optimizer\": optimizer_name,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"epochs\": epochs\n",
    "        })\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            for batch_features, batch_labels in train_loader:\n",
    "                batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "                outputs = model(batch_features)\n",
    "                loss = criterion(outputs, batch_labels)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        correct = total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_features, batch_labels in test_loader:\n",
    "                batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "                outputs = model(batch_features)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += batch_labels.size(0)\n",
    "                correct += (predicted == batch_labels).sum().item()\n",
    "\n",
    "        accuracy = correct / total\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "        # Log model\n",
    "        mlflow.pytorch.log_model(model, name=\"model\")\n",
    "\n",
    "        return accuracy\n",
    "\n",
    "# Setup MLflow experiment and callback\n",
    "mlflow.set_experiment(\"optuna_mynn_experiment2\")\n",
    "mlflow_callback = MLflowCallback(\n",
    "    tracking_uri=mlflow.get_tracking_uri(),\n",
    "    metric_name=\"accuracy\"\n",
    ")\n",
    "\n",
    "# Run Optuna optimization\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10, callbacks=[mlflow_callback])\n",
    "\n",
    "# Optional: log best trial manually\n",
    "best_trial = study.best_trial\n",
    "with mlflow.start_run(run_name=\"best_trial_summary\"):\n",
    "    mlflow.log_params(best_trial.params)\n",
    "    mlflow.log_metric(\"best_accuracy\", best_trial.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T13:56:34.297905Z",
     "start_time": "2025-06-18T13:56:34.277241Z"
    }
   },
   "outputs": [],
   "source": [
    "study.best_value, study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlflow ui\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
